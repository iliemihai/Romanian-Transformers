{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL USING ROMANIAN BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post we will take a pretrained model and we will create a classifiers on top of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers tokenizers pytorch-lightning torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import *\n",
    "import logging\n",
    "import os\n",
    "from functools import lru_cache\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from imbalanced_sampler import ImbalancedDatasetSampler\n",
    "from argparse import Namespace\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-Trained BERT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/dumitrescustefan/bert-base-romanian-cased-v1/config.json from cache at /home/mihai/.cache/torch/transformers/16f881d81e2cc1a24df63c9281832f2a67e993ce53cc89ffb92c86e198fa0fce.0238ce9e237411721966c916e09e62c904acebf01de9678d4263c97d3d95ec18\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50000\n",
      "}\n",
      "\n",
      "INFO:transformers.tokenization_utils:Model name 'dumitrescustefan/bert-base-romanian-cased-v1' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'dumitrescustefan/bert-base-romanian-cased-v1' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/dumitrescustefan/bert-base-romanian-cased-v1/vocab.txt from cache at /home/mihai/.cache/torch/transformers/8f484b8d8325d2eaf7ce7a1b76c3039ab5dac7f66e990510fec72516f38606eb.549839faf324dd95ad2a010a98d79e9ba649e1902543250d7f303dbe5911c2bb\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/dumitrescustefan/bert-base-romanian-cased-v1/added_tokens.json from cache at None\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/dumitrescustefan/bert-base-romanian-cased-v1/special_tokens_map.json from cache at None\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/dumitrescustefan/bert-base-romanian-cased-v1/tokenizer_config.json from cache at None\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/dumitrescustefan/bert-base-romanian-cased-v1/config.json from cache at /home/mihai/.cache/torch/transformers/16f881d81e2cc1a24df63c9281832f2a67e993ce53cc89ffb92c86e198fa0fce.0238ce9e237411721966c916e09e62c904acebf01de9678d4263c97d3d95ec18\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50000\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/dumitrescustefan/bert-base-romanian-cased-v1/pytorch_model.bin from cache at /home/mihai/.cache/torch/transformers/43f08c09359d4992b29f1910631e4813ab686ac589a0ef4ebb74e95217aeb8af.aeb64baccc31c441972d0f4a7d5306c3ccd091a9db58162dae7442f024699db7\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "config = BertConfig.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\", output_hidden_states=True)\n",
    "model = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sentence is: ['[CLS]', 'am', 'imprumut', '##at', 'cartea', 'acesta', '.', '[SEP]'] and it has the following ids : [2, 474, 48617, 368, 4435, 1330, 18, 3]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Am împrumutat cartea acesta.\"\n",
    "mark_sentence = \"[CLS]\" + sentence + \"[SEP]\"\n",
    "tokenized_sentence = tokenizer.tokenize(mark_sentence)\n",
    "enc_sentence = tokenizer.encode(sentence)\n",
    "print(\"Tokenized sentence is: {} and it has the following ids : {}\".format(tokenized_sentence, enc_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['controlul',\n",
       " 'schimba',\n",
       " '##alia',\n",
       " 'împrum',\n",
       " '##năsti',\n",
       " 'acordat',\n",
       " 'aste',\n",
       " '##ction',\n",
       " '##atia',\n",
       " '2003',\n",
       " 'mașini',\n",
       " 'PNL',\n",
       " 'dans',\n",
       " 'anexa',\n",
       " '##cilor',\n",
       " '##osc',\n",
       " 'învin',\n",
       " 'Transilv',\n",
       " 'oa',\n",
       " '##anților']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\t2\n",
      "printesa\t2\n",
      "a\t42240\n",
      "sar\t69\n",
      "##utat\t2610\n",
      "broa\t3452\n",
      "##sca\t38130\n",
      "dar\t2298\n",
      "aceasta\t592\n",
      "nu\t1239\n",
      "s\t411\n",
      "-\t87\n",
      "a\t17\n",
      "transformat\t69\n",
      "in\t8057\n",
      "print\t402\n",
      ".\t24930\n",
      "nu\t18\n",
      "am\t411\n",
      "gasit\t474\n",
      "cheia\t10177\n",
      "ca\t12685\n",
      "sa\t416\n",
      "deschid\t446\n",
      "broa\t14180\n",
      "##sca\t38130\n",
      "de\t2298\n",
      "la\t363\n",
      "usa\t392\n",
      ".\t19386\n",
      "[SEP]\t18\n"
     ]
    }
   ],
   "source": [
    "##create new example with omonymns\n",
    "sentences = \"Prințesa a sărutat broasca dar aceasta nu s-a transformat in prinț.\" \\\n",
    "            \"Nu am găsit cheia ca să deschid broasca de la ușă.\"\n",
    "\n",
    "# Add the special tokens.\n",
    "mark_sentences = \"[CLS] \" + sentences + \" [SEP]\"\n",
    "\n",
    "# Tokenize sentences into tokens\n",
    "tokenized_sentences = tokenizer.tokenize(mark_sentences)\n",
    "\n",
    "# Map tokens to ids in vocabulary\n",
    "ids_sentences = tokenizer.encode(mark_sentences)\n",
    "\n",
    "for tok, id in zip(tokenized_sentences, ids_sentences):\n",
    "    print(\"{}\\t{}\".format(tok, id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "ids_segments = [1] * len(ids_sentences)\n",
    "\n",
    "print(ids_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor(ids_sentences).unsqueeze(0)  # Batch size 1\n",
    "segments_tensor = torch.tensor(ids_segments).unsqueeze(0) # batch size 1 \n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor, segments_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Understand output layers\n",
    "last_hidden_states = outputs[0]\n",
    "# tensor of shape (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "pooler_output = outputs[1]\n",
    "# tensor of shape (batch_size, hidden_size)\n",
    "\n",
    "hidden_states = outputs[2]\n",
    "# list of tensors of shape (batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13\n",
      "Number of batches: 1\n",
      "Number of tokens: 33\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 3\n",
    "layer_i = 7\n",
    "vec = hidden_states[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 33, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "token_embeddings = token_embeddings.squeeze(1)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embedding representations for words and sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 16 x 4608\n"
     ]
    }
   ],
   "source": [
    "def get_tokkens_embeddings_concat(sentence, max_length=16):\n",
    "    # list with tokens embeddings for each token\n",
    "    token_vecs_concat = []\n",
    "    \n",
    "    ids_sentences = tokenizer.encode(sentence, add_special_tokens=True,\n",
    "                                    pad_to_max_length=True,\n",
    "                                    max_length=max_length)\n",
    "    ids_segments = [1] * len(ids_sentences)\n",
    "    input_tensor = torch.tensor(ids_sentences).unsqueeze(0)  # Batch size 1\n",
    "    segments_tensor = torch.tensor(ids_segments).unsqueeze(0) # batch size 1 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, _, hidden_states = model(input_tensor, segments_tensor)\n",
    "                                    \n",
    "    token_embeddings = torch.stack(hidden_states, dim=0).squeeze(1).permute(1,0,2)\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4], token[-5], token[-6]), dim=0)\n",
    "\n",
    "        token_vecs_concat.append(cat_vec)\n",
    "        \n",
    "    return token_vecs_concat\n",
    "\n",
    "tokens_emb = get_tokkens_embeddings_concat(\"Eu am fost in Vama Veche.\")\n",
    "print ('Shape is: %d x %d' % (len(tokens_emb), len(tokens_emb[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 16 x 768\n"
     ]
    }
   ],
   "source": [
    "def get_tokkens_embeddings_summ(sentence, max_length=16):\n",
    "    token_vecs_summ = []\n",
    "\n",
    "    ids_sentences = tokenizer.encode(sentence, add_special_tokens=True,\n",
    "                                    pad_to_max_length=True,\n",
    "                                    max_length=max_length)\n",
    "    ids_segments = [1] * len(ids_sentences)\n",
    "    input_tensor = torch.tensor(ids_sentences).unsqueeze(0)  # Batch size 1\n",
    "    segments_tensor = torch.tensor(ids_segments).unsqueeze(0) # batch size 1 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, _, hidden_states = model(input_tensor, segments_tensor)\n",
    "                                    \n",
    "    token_embeddings = torch.stack(hidden_states, dim=0).squeeze(1).permute(1,0,2)\n",
    "    \n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "        sum_vec = torch.sum(token[-6:], dim=0)\n",
    "\n",
    "        token_vecs_summ.append(sum_vec)\n",
    "\n",
    "    return token_vecs_summ\n",
    "    \n",
    "tokens_emb = get_tokkens_embeddings_summ(\"Aceasta este o propozitie.\")\n",
    "print ('Shape is: %d x %d' % (len(tokens_emb), len(tokens_emb[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_similarity(tokens_emb, idx1, idx2):\n",
    "    \n",
    "    tok1_emb = tokens_emb[idx1]\n",
    "    tok2_emb = tokens_emb[idx2]\n",
    "\n",
    "    output = cosine(tok1_emb, tok2_emb)\n",
    "    \n",
    "    return 1-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754744827747345\n",
      "0.5881729125976562\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"Am mers pe lac si am inotat in lac.\"\n",
    "sentence2 = \"Lebedele inotau pe lac si am dat cu lac pe unghii.\"\n",
    "tokens_emb1 = get_tokkens_embeddings_concat(sentence1)\n",
    "tokens_emb2 = get_tokkens_embeddings_concat(sentence2)\n",
    "\n",
    "print(tokens_similarity(tokens_emb1, 3, 9))\n",
    "print(tokens_similarity(tokens_emb2, 6, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Embeddings ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeddings(sentence, max_length=16):\n",
    "    \n",
    "    ids_sentences = tokenizer.encode(sentence, add_special_tokens=True,\n",
    "                                    pad_to_max_length=True,\n",
    "                                    max_length=max_length)\n",
    "    ids_segments = [1] * len(ids_sentences)\n",
    "    input_tensor = torch.tensor(ids_sentences).unsqueeze(0)  # Batch size 1\n",
    "    segments_tensor = torch.tensor(ids_segments).unsqueeze(0) # batch size 1 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, _, hidden_states = model(input_tensor, segments_tensor)\n",
    "    \n",
    "    token_vecs = hidden_states[12][0]\n",
    "\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    \n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2):\n",
    "    \n",
    "    sent1_emb = get_sentence_embeddings(sent1)\n",
    "    sent2_emb = get_sentence_embeddings(sent2)\n",
    "    \n",
    "    output = cosine(sent1_emb, sent2_emb)\n",
    "    \n",
    "    return 1-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8724686503410339\n",
      "0.7341930866241455\n",
      "0.7526880502700806\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"Am fost la doctor la un control\"\n",
    "sentence2 = \"Medicul a operat in salon\"\n",
    "sentence3 = \"Nu am fost niciodata atat de vesela\"\n",
    "\n",
    "print(sentence_similarity(sentence1, sentence2))\n",
    "print(sentence_similarity(sentence2, sentence3))\n",
    "print(sentence_similarity(sentence1, sentence3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENTENCE CLASSIFICATION WITH BERT ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_df = pd.read_csv(\"./ro/train.csv\")\n",
    "train_df.label = train_df.label.astype('category')\n",
    "\n",
    "test_df = pd.read_csv(\"./ro/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17941.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4736.087843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2982.913642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6727.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11093.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index\n",
       "count  17941.000000\n",
       "mean    4736.087843\n",
       "std     2982.913642\n",
       "min        0.000000\n",
       "25%     2242.000000\n",
       "50%     4485.000000\n",
       "75%     6727.000000\n",
       "max    11093.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training Label Distribution')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.label.hist()\n",
    "plt.title(\"Training Label Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acest document mi-a deschis cu adevarat ochii la ceea ce oamenii din afara statelor unite s-au gandit la atacurile din 11 septembrie. acest film a fost construit in mod expert si prezinta acest dezastru ca fiind mai mult decat un atac asupra pamantului american. urmarile acestui dezastru sunt previzionate din multe tari si perspective diferite. cred ca acest film ar trebui sa fie mai bine distribuit pentru acest punct. de asemenea, el ajuta in procesul de vindecare sa vada in cele din urma altceva decat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tine mancarea rece. ce altceva ii mai trebuie?\\nam frigiderul de vreun an, utilizare continua.\\nzgomotul e decent spre scazut daca esti in aceeasi incapere cu el. nu il auzi din dormitory cu usile inchise.\\ne un frigider ce sa zici despre el?\\no sa tina mancarea rece, la temperaturile indicate. recomand sa spalati bine dispenserul de lichide dupa utilizare ca sa nu se contamineze apa. da asta e de bun simt: d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>excelent\\nrecomand!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ca un rocker imbatranit, acest film mentioneaza heep and quo - cele doua trupe preferate ale mele vreodata - dar cu o distributie incredibila (toata lumea) - si povestea fantastica - imi place doar aceasta piesa de geniu creativ. nu-l pot recomanda mai mult - si mick jones a adaugat atat de mult (leaderul si scriitorul principal alaturi de cel mai mare cantaret rock - lou gramm) - am vazut aceasta mare lucrare mai mult de 10 ori - bill nighy - ce voce - si jimmy nail - talentul risipeste de la fiecare p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ei bine, a facut o groaza veche si foarte intunecata in casa. setare buna, care include personajul lui poe, el insusi, facand referire la poveste intr-un pub din londra. desi de aici este destul de mult un tip care a luat indrazneala sa viziteze casa intr-o noapte speciala care ruleaza din camera in camera, fie cauta sau evita oameni, este inca cea mai placuta. in plus, avem incantatoarea si enigmatica barbara steele. exista un dialog din lemn si niste biti si boboci inexplicabili, dar este atmosfera su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      2   \n",
       "3      3   \n",
       "4      4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text  \\\n",
       "0  acest document mi-a deschis cu adevarat ochii la ceea ce oamenii din afara statelor unite s-au gandit la atacurile din 11 septembrie. acest film a fost construit in mod expert si prezinta acest dezastru ca fiind mai mult decat un atac asupra pamantului american. urmarile acestui dezastru sunt previzionate din multe tari si perspective diferite. cred ca acest film ar trebui sa fie mai bine distribuit pentru acest punct. de asemenea, el ajuta in procesul de vindecare sa vada in cele din urma altceva decat...   \n",
       "1                                                                                                     tine mancarea rece. ce altceva ii mai trebuie?\\nam frigiderul de vreun an, utilizare continua.\\nzgomotul e decent spre scazut daca esti in aceeasi incapere cu el. nu il auzi din dormitory cu usile inchise.\\ne un frigider ce sa zici despre el?\\no sa tina mancarea rece, la temperaturile indicate. recomand sa spalati bine dispenserul de lichide dupa utilizare ca sa nu se contamineze apa. da asta e de bun simt: d   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              excelent\\nrecomand!   \n",
       "3  ca un rocker imbatranit, acest film mentioneaza heep and quo - cele doua trupe preferate ale mele vreodata - dar cu o distributie incredibila (toata lumea) - si povestea fantastica - imi place doar aceasta piesa de geniu creativ. nu-l pot recomanda mai mult - si mick jones a adaugat atat de mult (leaderul si scriitorul principal alaturi de cel mai mare cantaret rock - lou gramm) - am vazut aceasta mare lucrare mai mult de 10 ori - bill nighy - ce voce - si jimmy nail - talentul risipeste de la fiecare p...   \n",
       "4  ei bine, a facut o groaza veche si foarte intunecata in casa. setare buna, care include personajul lui poe, el insusi, facand referire la poveste intr-un pub din londra. desi de aici este destul de mult un tip care a luat indrazneala sa viziteze casa intr-o noapte speciala care ruleaza din camera in camera, fie cauta sau evita oameni, este inca cea mai placuta. in plus, avem incantatoarea si enigmatica barbara steele. exista un dialog din lemn si niste biti si boboci inexplicabili, dar este atmosfera su...   \n",
       "\n",
       "  label  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 512\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tine mancarea rece. ce altceva ii mai trebuie?\\nam frigiderul de vreun an, utilizare continua.\\nzgomotul e decent spre scazut daca esti in aceeasi incapere cu el. nu il auzi din dormitory cu usile inchise.\\ne un frigider ce sa zici despre el?\\no sa tina mancarea rece, la temperaturile indicate. recomand sa spalati bine dispenserul de lichide dupa utilizare ca sa nu se contamineze apa. da asta e de bun simt: d'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.values[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def mish(input):\n",
    "    '''\n",
    "    Applies the mish function element-wise:\n",
    "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
    "    See additional documentation for mish class.\n",
    "    '''\n",
    "    return input * torch.tanh(F.softplus(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "    '''\n",
    "    Applies the mish function element-wise:\n",
    "    mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + exp(x)))\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "    Examples:\n",
    "        >>> m = Mish()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init method.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Forward pass of the function.\n",
    "        '''\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, model,\n",
    "                output_size,\n",
    "                embedding_size=768,\n",
    "                dropout=0.1\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(embedding_size, embedding_size)\n",
    "        self.fc2 = nn.Linear(embedding_size, output_size)\n",
    "        self.activation = Mish()\n",
    "    \n",
    "    def forward(self, X):        \n",
    "        _, _, hidden_states = self.model(X)\n",
    "\n",
    "        sent_emb = torch.mean(hidden_states[12][0], dim=0)\n",
    "        \n",
    "        output = self.activation(self.dropout(self.fc1(sent_emb)))\n",
    "        output = self.dropout(self.fc2(output))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SentimentModel(model, output_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0359, 0.1031], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the classifier\n",
    "ids_sentences = tokenizer.encode(\"Ma simt foate rau.\", add_special_tokens=True,\n",
    "                                pad_to_max_length=True,\n",
    "                                max_length=256)\n",
    "\n",
    "input_tensor = torch.tensor(ids_sentences).unsqueeze(0)\n",
    "\n",
    "classifier(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.data = df\n",
    "        self.text = \"text\"\n",
    "        self.label = \"label\"\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.values[idx][1], self.data.values[idx][2]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('distractie excelenta de la inceput pana la sfarsit. spectacole minunate de belushi, beach, dalton & railsback. unele rasturnari si multe scene de actiune. filmul a fost facut pentru mine! linii amuzante in scenariu, muzica buna. dalton ca seriful dur si railsback ca \"raufacator\". trebuie sa recomand acest film tuturor fanilor de actiune si aventura! 10/10',\n",
       " 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SentimentDataset(train_df)\n",
    "train_dataset[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingModule(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.model = classifier(),\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.hparams = hparams\n",
    "        \n",
    "    def step(self, batch, step_name=\"train\"):\n",
    "        X, y = batch\n",
    "        loss = self.loss(self.forward(X), y)\n",
    "        loss_key = f\"{step_name}_loss\"\n",
    "        tensorboard_logs = {loss_key: loss}\n",
    "        \n",
    "        return { (\"loss\" if step_name == \"train\" else loss_key): loss, 'log': tensorboard_logs,\n",
    "               \"progress_bar\": {loss_key: loss}}\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"valid\")\n",
    "    \n",
    "    def validation_end(self, outputs):\n",
    "        loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        return {\"val_loss\": loss}\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.train_path, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.val_path)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_data_loader(self.hparams.test_path)\n",
    "                \n",
    "    def create_data_loader(self, df, shuffle=False):\n",
    "        return DataLoader(\n",
    "                    SentimentDataset(df),\n",
    "                    batch_size=self.hparams.batch_size,\n",
    "                    shuffle=False,\n",
    "                    sampler=ImbalancedDatasetSampler(train_dataset)\n",
    "                    )\n",
    "    \n",
    "    @lru_cache()\n",
    "    def total_steps(self):\n",
    "        return len(self.train_dataloader()) // self.hparams.accumulate_grad_batches * self.hparams.epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        ## use AdamW optimizer -- faster approach to training NNs\n",
    "        ## read: https://www.fast.ai/2018/07/02/adam-weight-decay/\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.lr)\n",
    "        lr_scheduler = get_linear_schedule_with_warmup(\n",
    "                    optimizer,\n",
    "                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                    num_training_steps=self.total_steps(),\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": lr_scheduler, \"interval\": \"step\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8ba52ef3ad9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_lr_finder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m hparams_tmp = Namespace(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_path' is not defined"
     ]
    }
   ],
   "source": [
    "lr=0.1 ## uper bound LR\n",
    "from torch_lr_finder import LRFinder\n",
    "hparams_tmp = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    epochs=1,\n",
    "    lr=lr,\n",
    "    accumulate_grad_batches=1,\n",
    ")\n",
    "module = TrainingModule(hparams_tmp)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(module.parameters(), lr=5e-7) ## lower bound LR\n",
    "lr_finder = LRFinder(module, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(module.train_dataloader(), end_lr=100, num_iter=100, accumulation_steps=hparams_tmp.accumulate_grad_batches)\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4 \n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot(show_lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(\n",
    "    train_path=train_path,\n",
    "    val_path=val_path,\n",
    "    test_path=test_path,\n",
    "    batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    epochs=1,\n",
    "    lr=lr,\n",
    "    accumulate_grad_batches=1\n",
    ")\n",
    "module = TrainingModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## garbage collection\n",
    "import gc; gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train roughly for about 10-15 minutes with GPU enabled.\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=hparams.epochs, progress_bar_refresh_rate=10,\n",
    "                     accumulate_grad_batches=hparams.accumulate_grad_batches)\n",
    "\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "    module.eval()\n",
    "    true_y, pred_y = [], []\n",
    "    for i, batch_ in enumerate(module.test_dataloader()):\n",
    "        (X, attn), y = batch_\n",
    "        batch = (X.cuda(), attn.cuda())\n",
    "        print(progress[i % len(progress)], end=\"\\r\")\n",
    "        y_pred = torch.argmax(module(batch), dim=1)\n",
    "        true_y.extend(y.cpu())\n",
    "        pred_y.extend(y_pred.cpu())\n",
    "print(\"\\n\" + \"_\" * 80)\n",
    "print(classification_report(true_y, pred_y, target_names=label2int.keys(), digits=len(emotions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
